import os
import json
import time
import datetime
import re
import random
import zipfile
import io
import sqlite3
import smtplib
import math
import asyncio
from contextlib import contextmanager
from typing import List, Optional, Dict, Any
from enum import Enum
from pydantic import BaseModel, Field
from email.mime.multipart import MIMEMultipart
from email.mime.base import MIMEBase
from email import encoders
from google import genai
from google.genai import types

# ==========================================
# 0. è¨­å®š & 2026å¹´ä»•æ§˜ (Headless / Embeddingãªã—)
# ==========================================
# ç’°å¢ƒå¤‰æ•°ã‹ã‚‰å–å¾—
API_KEY = os.environ.get("GEMINI_API_KEY")
GMAIL_USER = os.environ.get("GMAIL_USER")
GMAIL_PASS = os.environ.get("GMAIL_PASS")
TARGET_EMAIL = os.environ.get("GMAIL_USER") 

# ãƒ¢ãƒ‡ãƒ«è¨­å®š (2026å¹´ä»•æ§˜: Gemma 3 Limits Optimized)
MODEL_ULTRALONG = "gemini-2.0-flash"       # Gemini 2.0 Flash (ãƒ—ãƒ­ãƒƒãƒˆãƒ»é«˜å“è³ªãƒ»ã‚¹ã‚­ãƒ¼ãƒå¯¾å¿œ)
MODEL_LITE = "gemini-2.0-flash-lite"        # Gemma 3ç›¸å½“ã®è»½é‡ãƒ¢ãƒ‡ãƒ«ï¼ˆã‚¹ã‚­ãƒ¼ãƒå¯¾å¿œã®ãŸã‚Geminiç³»æ¨å¥¨ï¼‰
MODEL_PRO = "gemini-2.0-pro-exp"            # é«˜å“è³ªæ¨è«–ç”¨

DB_FILE = "factory_run.db" # è‡ªå‹•å®Ÿè¡Œç”¨ã«ä¸€æ™‚DBã¸å¤‰æ›´

# Global Config: Rate Limits
MIN_REQUEST_INTERVAL = 0.5

# ==========================================
# Pydantic Schemas (æ§‹é€ åŒ–å‡ºåŠ›ç”¨)
# ==========================================
class PlotScene(BaseModel):
    setup: str = Field(..., description="å°å…¥")
    conflict: str = Field(..., description="å±•é–‹")
    climax: str = Field(..., description="çµæœ«")

class PlotEpisode(BaseModel):
    ep_num: int
    title: str
    setup: str
    conflict: str
    climax: str
    resolution: str
    tension: int
    scenes: List[str]

class MCProfile(BaseModel):
    name: str
    tone: str
    personality: str
    ability: str
    monologue_style: str
    pronouns: Dict[str, str]
    keyword_dictionary: Dict[str, str]

class NovelStructure(BaseModel):
    title: str
    concept: str
    synopsis: str
    mc_profile: MCProfile
    plots: List[PlotEpisode]

class Phase2Structure(BaseModel):
    plots: List[PlotEpisode]

class WorldState(BaseModel):
    immutable: Dict[str, Any] = Field(default_factory=dict, description="ä¸å¤‰è¨­å®šï¼ˆæ€§åˆ¥ã€ç‰©ç†æ³•å‰‡ãªã©ï¼‰")
    mutable: Dict[str, Any] = Field(default_factory=dict, description="å¯å¤‰è¨­å®šï¼ˆå ´æ‰€ã€ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã€ç”Ÿæ­»ï¼‰")
    revealed: List[str] = Field(default_factory=list, description="èª­è€…ã«é–‹ç¤ºæ¸ˆã¿ã®è¨­å®šãƒªã‚¹ãƒˆ")

class SceneBlueprint(BaseModel):
    blueprint: str = Field(..., description="åŸ·ç­†ç”¨è©³ç´°è¨­è¨ˆå›³")
    required_info: str = Field(..., description="ä»Šå›é–‹ç¤ºã™ã¹ãæœ€å°é™ã®æƒ…å ±")

class ConsistencyResult(BaseModel):
    is_consistent: bool = Field(..., description="è¨­å®šçŸ›ç›¾ãŒãªã„ã‹")
    fatal_errors: List[str] = Field(default_factory=list, description="è‡´å‘½çš„ãªçŸ›ç›¾")
    minor_errors: List[str] = Field(default_factory=list, description="è»½å¾®ãªçŸ›ç›¾")
    rewrite_needed: bool = Field(..., description="ãƒªãƒ©ã‚¤ãƒˆãŒå¿…è¦ã‹")

class AnalysisResult(BaseModel):
    score_structure: int
    score_character: int
    score_hook: int
    score_volume: int
    total_score: int
    improvement_point: str

class MarketingAssets(BaseModel):
    evaluations: List[Dict[str, Any]] # ç°¡æ˜“åŒ–
    marketing_assets: Dict[str, Any]

# ==========================================
# ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆé›†ç´„ (PROMPT_TEMPLATES)
# ==========================================
PROMPT_TEMPLATES = {
    "system_rules": """# SYSTEM RULES: STRICT ADHERENCE REQUIRED
1. [PRONOUNS] ä¸»äººå…¬ã®ä¸€äººç§°ãƒ»äºŒäººç§°ã¯ä»¥ä¸‹ã‚’å³å®ˆã›ã‚ˆ: {pronouns}
   â€»ã€Œä¿ºã€è¨­å®šãªã®ã«ã€Œåƒ•ã€ã¨è¨€ã†ç­‰ã®ã‚­ãƒ£ãƒ©å´©å£Šã¯ç¦æ­¢ã™ã‚‹ã€‚
2. [KEYWORD DICTIONARY] ä»¥ä¸‹ã®ç”¨èªãƒ»ãƒ«ãƒ“ãƒ»ç‰¹æ®Šå‘¼ç§°ã‚’å¿…ãšä½¿ç”¨ã›ã‚ˆ: {keywords}
3. [MONOLOGUE STYLE] ç‹¬ç™½ãƒ»å¿ƒç†æå†™ã¯ä»¥ä¸‹ã®ç™–ã‚’åæ˜ ã›ã‚ˆ: {monologue_style}
   â€»å˜ãªã‚‹çŠ¶æ³èª¬æ˜ã§ã¯ãªãã€ä¸»äººå…¬ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã‚’é€šã—ãŸã€æ­ªã‚“ã ä¸–ç•Œè¦³ã€ã¨ã—ã¦æƒ…æ™¯ã‚’è¨˜è¿°ã›ã‚ˆã€‚
4. [NARRATIVE STYLE] åœ°ã®æ–‡ã®æ–‡ä½“ãƒ»é›°å›²æ°—: ã€Œ{style}ã€
   â€»ã“ã®æ–‡ä½“ã‚’å³å®ˆã—ã€æå†™ã®ãƒˆãƒ¼ãƒ³ã‚’çµ±ä¸€ã›ã‚ˆã€‚
5. [ANTI-CLICHÃ‰] ã€Œâ€•â€•ãã®æ™‚ã ã£ãŸã€ã€Œãµã¨ã€æ°—ã¥ãã¨ã€ã€Œé‹å‘½ã®æ­¯è»ŠãŒã€ç­‰ã®ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆè¡¨ç¾ã‚’å³ç¦ã¨ã™ã‚‹ã€‚ä»£ã‚ã‚Šã«ã€ç‰©ç†ç¾è±¡ï¼ˆå½±ã®ä¼¸ã³ã€æ°—æ¸©ã€å¿ƒæ‹æ•°ï¼‰ã®å¤‰åŒ–ã§äº‹æ…‹ã®æ€¥å¤‰ã‚’æå†™ã›ã‚ˆã€‚
--------------------------------------------------
""",
    "writing_rules": """
ã€è¶…é‡è¦: åŸ·ç­†å¯†åº¦ã‚’ç©¶æ¥µã¾ã§é«˜ã‚ã‚‹é‰„å‰‡ã€‘
AIç‰¹æœ‰ã®ã€Œè¦ç´„ç™–ã€ã‚’å®Œå…¨ã«æ¨ã¦ã€ä»¥ä¸‹ã®ãƒ«ãƒ¼ãƒ«ã§æå†™å¯†åº¦ã‚’æœ€å¤§åŒ–ã›ã‚ˆã€‚

1. **1è©±3ã‚·ãƒ¼ãƒ³åˆ¶**:
   1è©±ã‚’å¿…ãšã€Œ3ã¤ã®ç•°ãªã‚‹ã‚·ãƒ¼ãƒ³ï¼ˆå ´æ‰€ãƒ»æ™‚é–“ã®è»¢æ›ï¼‰ã€ã«åˆ†å‰²ã—ã¦æ§‹æˆã›ã‚ˆã€‚å„ã‚·ãƒ¼ãƒ³800æ–‡å­—ä»¥ä¸Šã‚’è²»ã‚„ã—ã€ã‚·ãƒ¼ãƒ³é–“ã«ã¯ã€Œç§»å‹•ã‚„æ™‚é–“çµŒéã€ã®æå†™ã‚’æŒŸã‚€ã“ã¨ã€‚

2. **ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒ»ã‚¢ãƒ³ã‚«ãƒ¼ï¼ˆäºˆå‚™å‹•ä½œï¼‰**:
   æ”»æ’ƒã‚„ç§»å‹•ãªã©ã®å‹•ä½œæå†™ã§ã¯ã€çµæœã‚’æ›¸ãå‰ã«å¿…ãš**ã€Œäºˆå‚™å‹•ä½œï¼ˆè¦–ç·šã®å‹•ãã€ç­‹è‚‰ã®ç·Šå¼µã€å‘¼å¸ã€æœã®æ“¦ã‚Œã‚‹éŸ³ï¼‰ã€ã‚’2è¡Œä»¥ä¸Šæå†™**ã—ã€ã‚¹ãƒ­ãƒ¼ãƒ¢ãƒ¼ã‚·ãƒ§ãƒ³ã®ã‚ˆã†ãªãƒªã‚¢ãƒªãƒ†ã‚£ã‚’å‡ºã™ã“ã¨ã€‚

3. **ãƒŠãƒ©ãƒ†ã‚£ãƒ–ãƒ»ãƒ«ãƒ¼ãƒ—**:
   ä¼šè©±ã‚·ãƒ¼ãƒ³ã¯**ã€Œ1.å°è©ã€â†’ã€Œ2.ãã®ç¬é–“ã®å¿ƒç†ã€â†’ã€Œ3.æƒ…æ™¯ï¼ˆé¢¨ã€å…‰ã€éŸ³ï¼‰ã€**ã®3ç‚¹ã‚»ãƒƒãƒˆã‚’ç¹°ã‚Šè¿”ã™æ§‹é€ ã«ã™ã‚‹ã“ã¨ã€‚ä¼šè©±æ–‡ã ã‘ã§ç‰©èªã‚’é€²è¡Œã•ã›ã‚‹ã“ã¨ã‚’å³ç¦ã¨ã™ã‚‹ã€‚

4. **Dynamic Pacingï¼ˆå‹•çš„æ¼”å‡ºï¼‰**:
   å„è©±ã®ãƒ—ãƒ­ãƒƒãƒˆå†…ã«ã‚ã‚‹ã€tensionã€å€¤ã‚’å‚ç…§ã—ã¦æ–‡ä½“ã‚’å¤‰ãˆã‚ˆã€‚
   - **Tension 70ä»¥ä¸Š**: ã€Œè¦–è¦šæƒ…å ±ãƒ»çŸ­æ–‡ä¸­å¿ƒã€ã§ã‚¹ãƒ”ãƒ¼ãƒ‰æ„Ÿã‚’é‡è¦–ã›ã‚ˆã€‚
   - **Tension 40ä»¥ä¸‹**: ã€Œå¿ƒç†æå†™ãƒ»è´è¦šæƒ…å ±ä¸­å¿ƒã€ã§æƒ…ç·’ã¨ä½™éŸ»ã‚’é‡è¦–ã›ã‚ˆã€‚
""",
    "cliffhanger_protocol": """
ã€ç©¶æ¥µã®ã€Œå¼•ãã€ç”Ÿæˆãƒ­ã‚¸ãƒƒã‚¯: Cliffhanger Protocolã€‘
å„ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã®çµæœ«ã¯ã€æ–‡è„ˆã«å¿œã˜ã¦æœ€ã‚‚åŠ¹æœçš„ãªã€Œå¼•ãã€ã‚’è‡ªå¾‹çš„ã«åˆ¤æ–­ã—ã€**ã€Œèª­è€…ãŒæ¬¡ã‚’èª­ã¾ãšã«ã„ã‚‰ã‚Œãªã„çŠ¶æ…‹ã€**ã‚’å¼·åˆ¶çš„ã«ä½œã‚Šå‡ºã›ã€‚

1. **é€†ç®—å¼ãƒ»ã‚´ãƒ¼ãƒ«åœ°ç‚¹å›ºå®š**:
   - ã‚ãªãŸã¯ã€Œçµæœ«ã®è¡æ’ƒã€ã‹ã‚‰é€†ç®—ã—ã¦ä¼ç·šã‚’å¼µã‚‹æ§‹æˆä½œå®¶ã§ã‚ã‚‹ã€‚
   - æœ¬æ–‡åŸ·ç­†å‰ã«ã€ãã®è©±ã®**ã€Œæœ€æ‚ªã€ã‚ã‚‹ã„ã¯æœ€é«˜ã®çµæœ«ï¼ˆæœ€å¾Œã®ä¸€è¡Œï¼‰ã€**ã‚’ç¢ºå®šã›ã‚ˆã€‚
   - ãã®ä¸€è¡ŒãŒèª­è€…ã«æœ€å¤§ã®è¡æ’ƒã‚’ä¸ãˆã‚‹ã‚ˆã†ã€ãã“ã«è‡³ã‚‹ã¾ã§ã®ä¼ç·šã€æœŸå¾…ã€èª¤èªã‚’ã‚·ãƒ¼ãƒ³1ãƒ»2ã«é…ç½®ã›ã‚ˆã€‚
   - çµæœ«ã‚’ã¼ã‹ã•ãªã„ã“ã¨ã€‚äºˆå®šèª¿å’Œãªçµ‚ã‚ã‚Šæ–¹ã‚’ã—ãªã„ã“ã¨ã€‚

2. **ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ãƒ»ã‚«ã‚¿ã‚¹ãƒˆãƒ­ãƒ•ã‚£**:
   - ã‚ãªãŸã¯è§£æ±ºã®1ç§’å‰ã«ç­†ã‚’ç½®ãã€å†·é…·ãªãƒ‡ã‚£ãƒ¬ã‚¯ã‚¿ãƒ¼ã§ã‚ã‚‹ã€‚
   - çµ¶ä½“çµ¶å‘½ã®ç¬é–“ã€ã‚ã‚‹ã„ã¯ç§˜å¯†ãŒæš´ã‹ã‚Œã‚‹**ã€Œç›´å‰ã€ã§ç‰©èªã‚’å¼·åˆ¶çµ‚äº†**ã›ã‚ˆã€‚
   - èª­è€…ãŒã€Œæ•‘ã„ã€ã‚„ã€Œç´å¾—ã€ã‚’å¾—ã‚‹è¨˜è¿°ã‚’ä¸€åˆ‡æ’é™¤ã›ã‚ˆã€‚å®‰å¿ƒã•ã›ãšã€è§£æ±ºã—ãã‚‰ãªã„ã“ã¨ã€‚
""",
    "formatting_rules": """
ã€æ¼”å‡ºæŒ‡ç¤ºã€‘
- ã€Œä¸‰ç‚¹ãƒªãƒ¼ãƒ€ãƒ¼ï¼ˆâ€¦â€¦ï¼‰ã®å¾Œã¯ã€ã‚ãˆã¦æ”¹è¡Œã—ã¦ç©ºç™½ã‚’ä½œã‚Œã€‚ãã®ç©ºç™½ã§èª­è€…ã®å¿ƒæ‹æ•°ã‚’ä¸Šã’ã‚ã€‚ã€
- ã€Œæœ€å¾Œã®ä¸€è¡Œã¯ã€15æ–‡å­—ä»¥å†…ã®çŸ­ã„ä¸€æ–‡ã§ã€é‡ãã€é‹­ãè¨€ã„æ”¾ã¦ã€‚ã€
- ã€Œè§£æ±ºç­–ï¼ˆãƒãƒ¼ãƒˆèƒ½åŠ›ã®ä½¿ç”¨ãªã©ï¼‰ã‚’æ€ã„ã¤ã„ãŸç¬é–“ã«ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã‚’åˆ‡ã‚Œã€‚ã€
"""
}

# ==========================================
# Formatter Class
# ==========================================
class TextFormatter:
    @staticmethod
    def format(text, k_dict=None):
        if not text: return ""
        text = text.replace("\\n", "\n")
        
        # 1. ä¸è¦ã‚¿ã‚°å‰Šé™¤
        text = re.sub(r'^[â– ã€\[#]?(?:ãƒ‘ãƒ¼ãƒˆ|Part|part|Chapter|section|å°å…¥|æœ¬ç­‹|çµæœ«|æ§‹æˆ|è¦ç´ ).*$', '', text, flags=re.MULTILINE)
        text = re.sub(r'^\s*[-*]{3,}\s*$', '', text, flags=re.MULTILINE)
        text = re.sub(r'ã€èª­è€…ã®åå¿œã€‘.*$', '', text, flags=re.DOTALL)
        text = re.sub(r'```json.*?```', '', text, flags=re.DOTALL) 

        # 2. ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ç½®æ›
        if k_dict:
            for term, ruby in k_dict.items():
                pattern = re.compile(re.escape(term) + r'(?!ã€Š)')
                text = pattern.sub(f"|{term}ã€Š{ruby}ã€‹", text)

        # 3. è¨˜å·æ­£è¦åŒ–ã¨ä½œæ³•å¾¹åº•
        text = text.replace("|", "ï½œ")
        # ä¸‰ç‚¹ãƒªãƒ¼ãƒ€ãƒ¼ã®æ­£è¦åŒ–ï¼ˆå¶æ•°å€‹ã‹ã¤2å€‹ä»¥ä¸Šï¼‰
        text = re.sub(r'â€¦+', 'â€¦â€¦', text)
        text = text.replace('â€¦â€¦', 'â€¦â€¦') # å¿µã®ãŸã‚
        # ãƒ€ãƒƒã‚·ãƒ¥ã®æ­£è¦åŒ–
        text = text.replace("â€”â€”", "â€•â€•").replace("--", "â€•â€•").replace("â€•", "â€•â€•")
        text = text.replace("â€•â€•â€•â€•", "â€•â€•")
        
        text = re.sub(r'^[ \tã€€]+(?=ã€Œ)', '', text, flags=re.MULTILINE)
        text = text.replace("ï½œ", "|") # DBä¿å­˜æ™‚ã¯ä¸€æ—¦åŠè§’ã«æˆ»ã™

        # 4. å¼·åˆ¶æ”¹è¡Œãƒ­ã‚¸ãƒƒã‚¯å‰Šé™¤ (æ®µè½ç¶­æŒã®ã¿)

        # 5. è¡Œå†æ§‹ç¯‰ï¼ˆç©ºè¡Œå¼·åˆ¶ãƒ»å­—ä¸‹ã’ï¼‰
        lines = []
        text = text.replace('\r\n', '\n')
        
        for line in text.split('\n'):
            line = line.strip()
            if not line: continue
            
            # ã‚»ãƒªãƒ•ã¨åœ°ã®æ–‡ã®å‡¦ç†
            if line.startswith(('ã€Œ', 'ã€', 'ï¼ˆ', 'ã€', '<', 'ã€ˆ')):
                lines.append("") # ã‚»ãƒªãƒ•å‰ç©ºè¡Œ
                lines.append(line)
                lines.append("") # ã‚»ãƒªãƒ•å¾Œç©ºè¡Œ
            else:
                lines.append(f"ã€€{line}")
                lines.append("") # æ®µè½å¾Œç©ºè¡Œ

        text = "\n".join(lines)

        # 6. ä½™åˆ†ãªç©ºç™½ã®å‰Šé™¤
        text = re.sub(r'\n{3,}', '\n\n', text)

        return text.strip()

# ==========================================
# 1. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ç®¡ç†
# ==========================================
class DatabaseManager:
    def __init__(self, db_path):
        self.db_path = db_path
        self._init_tables()

    @contextmanager
    def _get_conn(self):
        conn = sqlite3.connect(self.db_path, check_same_thread=False)
        conn.row_factory = sqlite3.Row
        try:
            yield conn
            conn.commit()
        except Exception as e:
            conn.rollback()
            raise e
        finally:
            conn.close()

    def _init_tables(self):
        with self._get_conn() as conn:
            conn.executescript('''
                CREATE TABLE IF NOT EXISTS books (
                    id INTEGER PRIMARY KEY AUTOINCREMENT, title TEXT, genre TEXT, concept TEXT,
                    synopsis TEXT, catchcopy TEXT, target_eps INTEGER, style_dna TEXT,
                    target_audience TEXT, special_ability TEXT DEFAULT '',
                    status TEXT DEFAULT 'active', created_at TEXT, marketing_data TEXT, sub_plots TEXT
                );
                CREATE TABLE IF NOT EXISTS bible (
                    id INTEGER PRIMARY KEY AUTOINCREMENT, book_id INTEGER, 
                    immutable TEXT, mutable TEXT, revealed TEXT,
                    last_updated TEXT
                );
                CREATE TABLE IF NOT EXISTS plot (
                    book_id INTEGER, ep_num INTEGER, title TEXT, summary TEXT,
                    main_event TEXT, sub_event TEXT, pacing_type TEXT,
                    tension INTEGER DEFAULT 50, cliffhanger_score INTEGER DEFAULT 0,
                    status TEXT DEFAULT 'planned', 
                    setup TEXT, conflict TEXT, climax TEXT, resolution TEXT,
                    scenes TEXT,
                    PRIMARY KEY(book_id, ep_num)
                );
                CREATE TABLE IF NOT EXISTS chapters (
                    book_id INTEGER, ep_num INTEGER, title TEXT, content TEXT,
                    score_story INTEGER, killer_phrase TEXT, reader_retention_score INTEGER,
                    ending_emotion TEXT, discomfort_score INTEGER DEFAULT 0, tags TEXT,
                    ai_insight TEXT, retention_data TEXT, summary TEXT, world_state TEXT,
                    created_at TEXT, PRIMARY KEY(book_id, ep_num)
                );
                CREATE TABLE IF NOT EXISTS characters (
                    id INTEGER PRIMARY KEY AUTOINCREMENT, book_id INTEGER, name TEXT, role TEXT, dna_json TEXT, monologue_style TEXT
                );
            ''')

    def execute(self, query, params=()):
        with self._get_conn() as conn:
            cursor = conn.execute(query, params)
            return cursor.lastrowid

    def fetch_all(self, query, params=()):
        with self._get_conn() as conn:
            return [dict(row) for row in conn.execute(query, params).fetchall()]
            
    def fetch_one(self, query, params=()):
        with self._get_conn() as conn:
            row = conn.execute(query, params).fetchone()
            return dict(row) if row else None

db = DatabaseManager(DB_FILE)

# ==========================================
# 2. Dynamic Bible System
# ==========================================
class DynamicBibleManager:
    def __init__(self, book_id):
        self.book_id = book_id
    
    def get_current_state(self) -> WorldState:
        row = db.fetch_one("SELECT * FROM bible WHERE book_id=? ORDER BY id DESC LIMIT 1", (self.book_id,))
        if not row:
            return WorldState()
        try:
            return WorldState(
                immutable=json.loads(row['immutable']) if row['immutable'] else {},
                mutable=json.loads(row['mutable']) if row['mutable'] else {},
                revealed=json.loads(row['revealed']) if row['revealed'] else []
            )
        except:
            return WorldState()

    def update_state(self, new_state: WorldState):
        db.execute(
            "INSERT INTO bible (book_id, immutable, mutable, revealed, last_updated) VALUES (?,?,?,?,?)",
            (
                self.book_id,
                json.dumps(new_state.immutable, ensure_ascii=False),
                json.dumps(new_state.mutable, ensure_ascii=False),
                json.dumps(new_state.revealed, ensure_ascii=False),
                datetime.datetime.now().isoformat()
            )
        )

    def get_prompt_context(self) -> str:
        state = self.get_current_state()
        return f"""
ã€WORLD STATE (Current)ã€‘
[IMMUTABLE - Do Not Change]: {json.dumps(state.immutable, ensure_ascii=False)}
[MUTABLE - Can Change]: {json.dumps(state.mutable, ensure_ascii=False)}
[REVEALED - Known to Reader]: {json.dumps(state.revealed, ensure_ascii=False)}
"""

# ==========================================
# 3. Adaptive Rate Limiter (Circuit Breaker)
# ==========================================
class AdaptiveRateLimiter:
    def __init__(self, initial_limit=5, min_limit=1):
        self.limit = initial_limit
        self.min_limit = min_limit
        self.semaphore = asyncio.Semaphore(initial_limit)
        self.lock = asyncio.Lock()
    
    async def acquire(self):
        await self.semaphore.acquire()

    def release(self):
        self.semaphore.release()

    async def report_success(self):
        async with self.lock:
            if self.limit < 10: # Max limit cap
                self.limit += 1
                # Increase semaphore capacity strictly
                # (Simple implementations often just recreate semaphore or release extra, 
                # here we just rely on future acquires being faster if we could dynamically resize.
                # Since asyncio semaphore doesn't support resize easily, we accept strict backoff
                # but lazy expansion or just keep semantic limit high and use sleep).
                pass

    async def report_failure(self):
        async with self.lock:
            old_limit = self.limit
            self.limit = max(self.min_limit, self.limit // 2)
            print(f"ğŸ“‰ Circuit Breaker Triggered: Limit reduced {old_limit} -> {self.limit}")
            await asyncio.sleep(5) # Cooldown
            
            # Drain semaphore to match new limit is complex, 
            # instead we simply sleep to simulate backpressure.

# ==========================================
# 4. ULTRA Engine (Autopilot & Mobile Opt)
# ==========================================
class UltraEngine:
    def __init__(self, api_key):
        self.client = genai.Client(api_key=api_key) if api_key else None
        self.rate_limiter = AdaptiveRateLimiter(initial_limit=5)
        self.safety_settings = [
            types.SafetySetting(category="HARM_CATEGORY_HATE_SPEECH", threshold="BLOCK_NONE"),
            types.SafetySetting(category="HARM_CATEGORY_HARASSMENT", threshold="BLOCK_NONE"),
            types.SafetySetting(category="HARM_CATEGORY_SEXUALLY_EXPLICIT", threshold="BLOCK_NONE"),
            types.SafetySetting(category="HARM_CATEGORY_DANGEROUS_CONTENT", threshold="BLOCK_NONE"),
        ]

    def _generate_system_rules(self, mc_profile, style="æ¨™æº–"):
        pronouns_json = json.dumps(mc_profile.get('pronouns', {}), ensure_ascii=False)
        keywords_json = json.dumps(mc_profile.get('keyword_dictionary', {}), ensure_ascii=False)
        monologue = mc_profile.get('monologue_style', 'æ¨™æº–')
        return PROMPT_TEMPLATES["system_rules"].format(pronouns=pronouns_json, keywords=keywords_json, monologue_style=monologue, style=style)

    # ---------------------------------------------------------
    # Retry Wrappers for Stability & Circuit Breaker
    # ---------------------------------------------------------
    async def _generate_with_retry(self, model, contents, config, retries=10, initial_delay=2.0):
        """éåŒæœŸç‰ˆ: ã‚µãƒ¼ã‚­ãƒƒãƒˆãƒ–ãƒ¬ãƒ¼ã‚«ãƒ¼ä»˜ããƒªãƒˆãƒ©ã‚¤"""
        await self.rate_limiter.acquire()
        try:
            for attempt in range(retries):
                try:
                    # ã‚¹ã‚­ãƒ¼ãƒãŒã‚ã‚‹å ´åˆã¯æ§‹é€ åŒ–ãƒ¢ãƒ¼ãƒ‰
                    response = await self.client.aio.models.generate_content(
                        model=model, 
                        contents=contents, 
                        config=config
                    )
                    await self.rate_limiter.report_success()
                    return response
                except Exception as e:
                    error_str = str(e)
                    is_429 = "429" in error_str or "ResourceExhausted" in error_str
                    
                    if is_429:
                        await self.rate_limiter.report_failure()
                        wait_time = initial_delay * (2 ** attempt) + random.uniform(1, 3)
                        print(f"âš ï¸ Quota Limit. Sleeping {wait_time:.2f}s...")
                        await asyncio.sleep(wait_time)
                    else:
                        print(f"âš ï¸ API Error: {e}. Retrying...")
                        await asyncio.sleep(2)
            raise Exception("Max retries exceeded")
        finally:
            self.rate_limiter.release()

    # ---------------------------------------------------------
    # Core Logic
    # ---------------------------------------------------------

    async def generate_universe_blueprint_phase1(self, genre, style, mc_personality, mc_tone, keywords):
        """ç¬¬1æ®µéš: æ§‹é€ åŒ–å‡ºåŠ›ã‚’ç”¨ã„ãŸãƒ—ãƒ­ãƒƒãƒˆç”Ÿæˆ"""
        print("Step 1: Hyper-Resolution Plot Generation Phase 1 (Ep 1-13)...")
        
        prompt = f"""
ã‚ãªãŸã¯Webå°èª¬ã®ç¥ç´šãƒ—ãƒ­ãƒƒãƒˆã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒˆã§ã™ã€‚
ã‚¸ãƒ£ãƒ³ãƒ«ã€Œ{genre}ã€ã§ã€èª­è€…ã‚’ç†±ç‹‚ã•ã›ã‚‹**å…¨25è©±å®Œçµã®ç‰©èªæ§‹é€ **ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚

ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼æŒ‡å®šã®çµ¶å¯¾æ¡ä»¶ã€‘
1. æ–‡ä½“: ã€Œ{style}ã€
2. ä¸»äººå…¬: æ€§æ ¼{mc_personality}, å£èª¿ã€Œ{mc_tone}ã€
3. ãƒ†ãƒ¼ãƒ: {keywords}

ã€Task: Phase 1 (Ep 1-13)ã€‘
ä½œå“è¨­å®šã¨ã€ç¬¬1è©±ã€œç¬¬13è©±ã®è©³ç´°ãƒ—ãƒ­ãƒƒãƒˆã‚’ä½œæˆã›ã‚ˆã€‚
"""
        try:
            res = await self._generate_with_retry(
                model=MODEL_ULTRALONG,
                contents=prompt,
                config=types.GenerateContentConfig(
                    response_mime_type="application/json",
                    response_schema=NovelStructure,
                    safety_settings=self.safety_settings
                )
            )
            # Pydanticãƒ¢ãƒ‡ãƒ«ã¨ã—ã¦ãƒ‘ãƒ¼ã‚¹ã•ã‚ŒãŸçµæœã‚’è¾æ›¸åŒ–
            return json.loads(res.text)
        except Exception as e:
            print(f"Plot Phase 1 Error: {e}")
            return None

    async def generate_universe_blueprint_phase2(self, genre, style, mc_personality, mc_tone, keywords, data1):
        """ç¬¬2æ®µéš: 14è©±ã€œ25è©±ã®ç”Ÿæˆ"""
        print("Step 1 (Parallel): Hyper-Resolution Plot Generation Phase 2 (Ep 14-25)...")
        
        context_summ = "\n".join([f"Ep{p['ep_num']}: {p['resolution'][:50]}..." for p in data1['plots']])
        prompt = f"""
ã‚ãªãŸã¯Webå°èª¬ã®ç¥ç´šãƒ—ãƒ­ãƒƒãƒˆã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒˆã§ã™ã€‚
å…¨25è©±å®Œçµã®ç‰©èªæ§‹é€ ã®å¾ŒåŠã‚’ä½œæˆã—ã¾ã™ã€‚

ã€ã“ã‚Œã¾ã§ã®æµã‚Œ (Ep1-13)ã€‘
{context_summ}

ã€Task: Phase 2 (Ep 14-25)ã€‘
å‰å›ã®ç¶šãã¨ã—ã¦ã€ç¬¬14è©±ã€œç¬¬25è©±ï¼ˆæœ€çµ‚è©±ï¼‰ã‚’ä½œæˆã›ã‚ˆã€‚
"""
        try:
            res = await self._generate_with_retry(
                model=MODEL_ULTRALONG,
                contents=prompt,
                config=types.GenerateContentConfig(
                    response_mime_type="application/json",
                    response_schema=Phase2Structure,
                    safety_settings=self.safety_settings
                )
            )
            return json.loads(res.text)
        except Exception as e:
            print(f"Plot Phase 2 Error: {e}")
            return None

    async def evaluate_consistency(self, ep_text, bible_manager) -> ConsistencyResult:
        """ã€æ§‹é€ æ”¹é©ã€‘ãƒªãƒ©ã‚¤ãƒˆè¦å¦ã®è«–ç†åˆ¤å®š"""
        state = bible_manager.get_current_state()
        prompt = f"""
ã‚ãªãŸã¯ç‰©èªã®æ•´åˆæ€§ã‚’ç›£æŸ»ã™ã‚‹AIãƒ­ã‚¸ãƒƒã‚¯ã§ã™ã€‚
ä»¥ä¸‹ã®ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰æœ¬æ–‡ã¨ã€ŒBibleï¼ˆä¸–ç•Œè¨­å®šï¼‰ã€ã‚’æ¯”è¼ƒã—ã€çŸ›ç›¾ã‚’æ¤œå‡ºã—ã¦ãã ã•ã„ã€‚

ã€Bibleã€‘
Immutable: {json.dumps(state.immutable, ensure_ascii=False)}
Mutable: {json.dumps(state.mutable, ensure_ascii=False)}

ã€Episode Textã€‘
{ep_text[:3000]}... (Excerpt)

åˆ¤å®šåŸºæº–:
1. æ­»ã‚“ã ã¯ãšã®ã‚­ãƒ£ãƒ©ãŒç”Ÿãã¦ã„ãªã„ã‹ï¼Ÿ
2. è¨­å®šã•ã‚ŒãŸç‰©ç†æ³•å‰‡ã‚„èƒ½åŠ›ã«é•åã—ã¦ã„ãªã„ã‹ï¼Ÿ
3. ã‚­ãƒ£ãƒ©ã®å£èª¿ã‚„ä¸€äººç§°ï¼ˆBibleå¤–ã ãŒæ–‡è„ˆã§åˆ¤æ–­ï¼‰ãŒå´©å£Šã—ã¦ã„ãªã„ã‹ï¼Ÿ

é‡å¤§ãªçŸ›ç›¾ãŒã‚ã‚‹å ´åˆã¯ rewrite_needed: true ã¨ã›ã‚ˆã€‚
"""
        try:
            res = await self._generate_with_retry(
                model=MODEL_LITE,
                contents=prompt,
                config=types.GenerateContentConfig(
                    response_mime_type="application/json",
                    response_schema=ConsistencyResult,
                    safety_settings=self.safety_settings
                )
            )
            return ConsistencyResult.model_validate_json(res.text)
        except Exception as e:
            print(f"Consistency Check Error: {e}")
            return ConsistencyResult(is_consistent=True, fatal_errors=[], minor_errors=[], rewrite_needed=False)

    async def sync_with_chapter(self, bible_manager, chapter_text):
        """ã€çŸ¥èƒ½çµ±åˆã€‘æœ¬æ–‡ã‹ã‚‰Bibleã‚’è‡ªå‹•æ›´æ–°"""
        current = bible_manager.get_current_state()
        prompt = f"""
ã‚ãªãŸã¯ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ç®¡ç†è€…ã§ã™ã€‚
ä»¥ä¸‹ã®ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰æœ¬æ–‡ã‹ã‚‰ã€Œæ–°ãŸã«ç¢ºå®šã—ãŸè¨­å®šã€ã€Œå¤‰åŒ–ã—ãŸã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã€ã€Œèª­è€…ã«é–‹ç¤ºã•ã‚ŒãŸç§˜å¯†ã€ã‚’æŠ½å‡ºã—ã€
WorldStateã‚’æ›´æ–°ã—ã¦ãã ã•ã„ã€‚

ã€Current Stateã€‘
{json.dumps(current.model_dump(), ensure_ascii=False)}

ã€Episode Textã€‘
{chapter_text}

Task:
1. Immutable: åŸºæœ¬çš„ã«å¤‰æ›´ãªã—ã€‚æ–°äº‹å®ŸãŒã‚ã‚Œã°è¿½åŠ ã€‚
2. Mutable: ä½ç½®ç§»å‹•ã€ã‚¢ã‚¤ãƒ†ãƒ å¢—æ¸›ã€ç”Ÿæ­»å¤‰åŒ–ã‚’åæ˜ ã€‚
3. Revealed: æœ¬æ–‡ä¸­ã§èª­è€…ã«èª¬æ˜ã•ã‚ŒãŸç”¨èªã‚„è¨­å®šã‚’è¿½åŠ ã€‚
"""
        try:
            res = await self._generate_with_retry(
                model=MODEL_LITE,
                contents=prompt,
                config=types.GenerateContentConfig(
                    response_mime_type="application/json",
                    response_schema=WorldState,
                    safety_settings=self.safety_settings
                )
            )
            new_state = WorldState.model_validate_json(res.text)
            bible_manager.update_state(new_state)
        except Exception as e:
            print(f"Bible Sync Error: {e}")

    async def write_episodes(self, book_data, start_ep, end_ep, style_dna_str="æ¨™æº–", target_model=MODEL_LITE, rewrite_instruction=None, semaphore=None):
        """ã€åŸ·ç­†æ´—ç·´ã€‘ãƒã‚¤ãƒ‘ãƒ¼ãƒ»ãƒŠãƒ©ãƒ†ã‚£ãƒ–ãƒ»ã‚¨ãƒ³ã‚¸ãƒ³"""
        
        all_plots = sorted(book_data['plots'], key=lambda x: x.get('ep_num', 999))
        target_plots = [p for p in all_plots if start_ep <= p.get('ep_num', -1) <= end_ep]
        if not target_plots: return None

        full_chapters = []
        bible_manager = DynamicBibleManager(book_data['book_id'])
        
        # å‰è©±ã®æ–‡è„ˆå–å¾— (Bridge Logicç”¨)
        prev_ep_row = db.fetch_one("SELECT content, summary FROM chapters WHERE book_id=? AND ep_num=? ORDER BY ep_num DESC LIMIT 1", (book_data['book_id'], start_ep - 1))
        prev_context_text = prev_ep_row['content'][-500:] if prev_ep_row and prev_ep_row['content'] else "ï¼ˆç‰©èªé–‹å§‹ï¼‰"

        system_rules = self._generate_system_rules(book_data['mc_profile'], style=style_dna_str)
        mc_name = book_data['mc_profile'].get('name', 'ä¸»äººå…¬')
        
        # Vocal Persona Setup
        vocab_filter = f"""
ã€Vocal Persona: {mc_name}ã€‘
- çŸ¥è­˜ãƒ¬ãƒ™ãƒ«: ä¸€èˆ¬äººãƒ¬ãƒ™ãƒ«ï¼ˆå°‚é–€ç”¨èªã¯çŸ¥ã‚‰ãªã„ã“ã¨ï¼‰
- ç¦æ­¢èªå½™: {json.dumps(book_data['mc_profile'].get('keyword_dictionary', {}), ensure_ascii=False)} ä»¥å¤–ã®é›£è§£ãªè¨€è‘‰
- åˆ¶ç´„: ã“ã®ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ãŒçŸ¥ã‚Šå¾—ãªã„æƒ…å ±ã¯ã€åœ°ã®æ–‡ã§ã‚‚çµ¶å¯¾ã«æå†™ã—ãªã„ã“ã¨ã€‚
"""

        for plot in target_plots:
            ep_num = plot['ep_num']
            print(f"Hyper-Narrative Engine Writing Ep {ep_num}...")
            
            full_content = ""
            current_text_tail = prev_context_text
            
            scenes = plot.get('scenes', [plot.get('setup',''), plot.get('conflict',''), plot.get('climax','') + plot.get('resolution','')])
            
            for part_idx, scene_plot in enumerate(scenes, 1):
                # A. æƒ…å ±é–‹ç¤ºåˆ¶é™ (Show, Don't Tell)
                bible_state = bible_manager.get_current_state()
                revealed_list = bible_state.revealed
                
                # --- Step 2: Segment Design (Gemma 3 27B) ---
                design_prompt = f"""
{system_rules}
{vocab_filter}
ã€Role: Architect (Gemma 3 27B)ã€‘
ä»¥ä¸‹ã®ãƒ—ãƒ­ãƒƒãƒˆã«åŸºã¥ãã€ã‚·ãƒ¼ãƒ³ã®ã€ŒåŸ·ç­†ç”¨è©³ç´°è¨­è¨ˆå›³ã€ã¨ã€Œæƒ…å ±é–‹ç¤ºæˆ¦ç•¥ã€ã‚’ç­–å®šã›ã‚ˆã€‚

ã€Current Scene Plotã€‘
{scene_plot}
ã€Bible Contextã€‘
{bible_manager.get_prompt_context()}

ã€Constraint: Show, Don't Tellã€‘
1. èª­è€…ã«ä¼ãˆã‚‹ã¹ãã€Œæ–°ã—ã„è¨­å®šã€ã‚’Bibleã‹ã‚‰**1ã¤ã ã‘**é¸ã¹ã€‚(required_info)
2. æ—¢ã«é–‹ç¤ºæ¸ˆã¿ãƒªã‚¹ãƒˆï¼ˆ{json.dumps(revealed_list, ensure_ascii=False)}ï¼‰ã«ã‚ã‚‹æƒ…å ±ã¯ã€èª¬æ˜ã›ãšå½“ç„¶ã®å‰æã¨ã—ã¦æ‰±ãˆã€‚
"""
                blueprint_data = None
                async with semaphore:
                    try:
                        res = await self._generate_with_retry(
                            model=MODEL_PRO, 
                            contents=design_prompt,
                            config=types.GenerateContentConfig(
                                response_mime_type="application/json",
                                response_schema=SceneBlueprint,
                                safety_settings=self.safety_settings
                            )
                        )
                        blueprint_data = SceneBlueprint.model_validate_json(res.text)
                    except Exception as e:
                        print(f"Design Error Ep{ep_num}-{part_idx}: {e}")
                        blueprint_data = SceneBlueprint(blueprint=scene_plot, required_info="ãªã—")

                # --- Step 3: Focused Writing (Gemma 3 12B) ---
                # C. è«–ç†çš„æ¥ç¶š (Bridge Logic)
                bridge_instruction = f"""
ã€Bridge Logicã€‘
å‰ã‚·ãƒ¼ãƒ³ã®æœ«å°¾: "...{current_text_tail}"
æŒ‡ç¤º: å‰ã‚·ãƒ¼ãƒ³ã®ã€Œæ„Ÿæƒ…ã®ä½™éŸ»ã€ã‚’å†’é ­ä¸€è¡Œç›®ã§å¼•ãç¶™ãã€ãªãœæ¬¡ã®å ´æ‰€ã«ç§»å‹•ã™ã‚‹ã®ã‹ã€ãã®ã€Œå‹•æ©Ÿã€ã‚’å¿…ãšæå†™ã›ã‚ˆã€‚
"""
                write_prompt = f"""
{system_rules}
{vocab_filter}
{bridge_instruction}
ã€Role: Writer (Gemma 3 12B)ã€‘
Blueprintã«å¾“ã„ã€ã‚·ãƒ¼ãƒ³ã‚’åŸ·ç­†ã›ã‚ˆã€‚

ã€Blueprintã€‘
{blueprint_data.blueprint}

ã€Mandatory New Info (Insert naturally)ã€‘
{blueprint_data.required_info}

ã€Rewrite Instruction (Marketing Feedback)ã€‘
{rewrite_instruction if rewrite_instruction else "ç‰¹ã«ãªã—"}
"""
                scene_text = ""
                async with semaphore:
                    try:
                        res = await self._generate_with_retry(
                            model=MODEL_LITE, 
                            contents=write_prompt,
                            config=types.GenerateContentConfig(safety_settings=self.safety_settings) # Text Output
                        )
                        scene_text = res.text
                    except Exception as e:
                        print(f"Writing Error Ep{ep_num}-{part_idx}: {e}")

                cleaned_part = scene_text.strip()
                full_content += cleaned_part + "\n\n"
                current_text_tail = cleaned_part[-200:]

            # --- Step 4: Auto-Sync Bible ---
            await self.sync_with_chapter(bible_manager, full_content)

            # ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰å®Œäº†å‡¦ç†
            full_chapters.append({
                "ep_num": ep_num,
                "title": plot['title'],
                "content": full_content,
                "summary": plot.get('resolution', '')[:100],
                "world_state": bible_manager.get_current_state().model_dump()
            })

        return {"chapters": full_chapters}

    async def _summarize_chunk(self, text_chunk, start_ep, end_ep, prev_summary="", next_summary=""):
        """ã€å†…éƒ¨ãƒ˜ãƒ«ãƒ‘ãƒ¼ã€‘ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ç¾¤ã‚’åœ§ç¸®è¦ç´„ã™ã‚‹"""
        prompt = f"""
ã€Task: Context Compressionã€‘ ä»¥ä¸‹ã®ç¬¬{start_ep}è©±ã€œç¬¬{end_ep}è©±ã®æœ¬æ–‡ã‚’ã€ç‰©èªã®é‡è¦ãƒã‚¤ãƒ³ãƒˆï¼ˆä¼ç·šãƒ»æ„Ÿæƒ…ãƒ»çµæœ«ï¼‰ã‚’æ¼ã‚‰ã•ãšã€å…¨ä½“ã§1000æ–‡å­—ç¨‹åº¦ã«ã€Œæ¿ƒç¸®è¦ç´„ã€ã›ã‚ˆã€‚

ã€Text Chunk (Ep{start_ep}-{end_ep})ã€‘
{text_chunk} 
"""
        try:
            res = await self._generate_with_retry(
                model=MODEL_LITE,
                contents=prompt,
                config=types.GenerateContentConfig(safety_settings=self.safety_settings)
            )
            return res.text.strip()
        except Exception as e:
            return text_chunk[:1000]

    async def analyze_and_create_assets(self, book_id):
        """ã€å®‰å®šåŒ–ã€‘ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãƒ«ãƒ¼ãƒ—çµ±åˆ"""
        print("Starting Recursive Analysis (Sliding Window)...")
        
        chapters = db.fetch_all("SELECT ep_num, title, summary, content FROM chapters WHERE book_id=? ORDER BY ep_num", (book_id,))
        book_info = db.fetch_one("SELECT title FROM books WHERE id=?", (book_id,))
        if not chapters: return [], [], None

        # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆåœ§ç¸®
        chunk_size = 5
        summary_tasks = []
        for i in range(0, len(chapters), chunk_size):
            chunk = chapters[i : i + chunk_size]
            full_text = "\n".join([f"Ep{c['ep_num']} {c['title']}:\n{c['content']}" for c in chunk])
            summary_tasks.append(self._summarize_chunk(full_text, chunk[0]['ep_num'], chunk[-1]['ep_num']))
        
        compressed_summaries = await asyncio.gather(*summary_tasks)
        master_context = "\n\n".join(compressed_summaries)
        
        prompt = f"""
ã‚ãªãŸã¯Webå°èª¬ã®æ•è…•ç·¨é›†è€…å…¼ãƒãƒ¼ã‚±ã‚¿ãƒ¼ã§ã™ã€‚
ä»¥ä¸‹ã®ã‚¿ã‚¹ã‚¯ã‚’ä¸€æ‹¬å®Ÿè¡Œã—ã€JSONã§å‡ºåŠ›ã›ã‚ˆã€‚

Task 1: å„è©±ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚° & æ”¹å–„ææ¡ˆ
Task 2: ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°ç´ æç”Ÿæˆ (ã‚­ãƒ£ãƒƒãƒã‚³ãƒ”ãƒ¼ã€ã‚¿ã‚°ã€è¿‘æ³ãƒãƒ¼ãƒˆ)

ã€ä½œå“ã‚¿ã‚¤ãƒˆãƒ«ã€‘{book_info['title']}
ã€ç‰©èªå…¨ä½“ãƒ€ã‚¤ã‚¸ã‚§ã‚¹ãƒˆã€‘
{master_context}
"""
        try:
            res = await self._generate_with_retry(
                model=MODEL_LITE,
                contents=prompt,
                config=types.GenerateContentConfig(
                    response_mime_type="application/json",
                    response_schema=MarketingAssets,
                    safety_settings=self.safety_settings
                )
            )
            data = MarketingAssets.model_validate_json(res.text)
            
            # --- æ§‹é€ æ”¹é©: é–¾å€¤å»ƒæ­¢ã¨è«–ç†åˆ¤å®šã¸ã®ç§»è¡Œ ---
            # ã“ã“ã§ã¯ã‚¹ã‚³ã‚¢ã‚‚è¦‹ã‚‹ãŒã€å¾Œã®ãƒ—ãƒ­ã‚»ã‚¹ã§ evaluate_consistency ã‚’å‘¼ã¶ãŸã‚ã®ãƒªã‚¹ãƒˆã‚¢ãƒƒãƒ—ã‚’è¡Œã†
            rewrite_target_eps = []
            bible_manager = DynamicBibleManager(book_id)
            
            for evaluation in data.evaluations:
                # ä½ã‚¹ã‚³ã‚¢ã¾ãŸã¯ "improvement_point" ã«é‡å¤§ãªæŒ‡æ‘˜ãŒã‚ã‚‹å ´åˆ
                ep_num = evaluation.get('ep_num')
                # ã“ã“ã§Consistency Checkã‚’éåŒæœŸã§èµ°ã‚‰ã›ã‚‹ã®ã‚‚æ‰‹ã ãŒã€ä»Šå›ã¯ãƒªãƒ©ã‚¤ãƒˆå€™è£œã¨ã—ã¦æŒ™ã’ã€
                # ãƒªãƒ©ã‚¤ãƒˆãƒ«ãƒ¼ãƒ—å†…ã§ evaluate_consistency ã‚’å‘¼ã¶è¨­è¨ˆã¨ã™ã‚‹ã€‚
                if evaluation.get('total_score', 0) < 60: # æœ€ä½é™ã®è¶³åˆ‡ã‚Š
                     rewrite_target_eps.append(ep_num)
            
            # DBæ›´æ–°
            db.execute("UPDATE books SET marketing_data=? WHERE id=?", (json.dumps(data.marketing_assets, ensure_ascii=False), book_id))
            
            return data.evaluations, rewrite_target_eps, data.marketing_assets
            
        except Exception as e:
            print(f"Analysis Error: {e}")
            return [], [], None

    async def rewrite_target_episodes(self, book_data, target_ep_ids, evaluations, style_dna_str="æ¨™æº–"):
        """ã€å®‰å®šåŒ–ã€‘ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°ãƒ»ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãƒ«ãƒ¼ãƒ—"""
        rewritten_count = 0
        semaphore = asyncio.Semaphore(2) 
        
        eval_map = {e['ep_num']: e for e in evaluations}
        tasks = []

        bible_manager = DynamicBibleManager(book_data['book_id'])

        for ep_id in target_ep_ids:
            # 1. æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯ (Consistency Check)
            chapter_row = db.fetch_one("SELECT content FROM chapters WHERE book_id=? AND ep_num=?", (book_data['book_id'], ep_id))
            consistency = await self.evaluate_consistency(chapter_row['content'], bible_manager)
            
            if not consistency.rewrite_needed and ep_id not in target_ep_ids:
                continue

            # 2. ãƒãƒ¼ã‚¸: ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°æŒ‡æ‘˜ + æ•´åˆæ€§ã‚¨ãƒ©ãƒ¼
            eval_data = eval_map.get(ep_id, {})
            marketing_instruction = eval_data.get('improvement_point', "")
            consistency_instruction = f"çŸ›ç›¾ä¿®æ­£: {','.join(consistency.fatal_errors)}" if consistency.fatal_errors else ""
            
            instruction = f"ã€ç·¨é›†æŒ‡ç¤ºã€‘\n{marketing_instruction}\n{consistency_instruction}"
            
            tasks.append(self.write_episodes(
                book_data, 
                ep_id, 
                ep_id, 
                style_dna_str=style_dna_str, 
                target_model=MODEL_PRO, 
                rewrite_instruction=instruction,
                semaphore=semaphore
            ))
            
        results = await asyncio.gather(*tasks)
        
        for res in results:
            if res and 'chapters' in res:
                self.save_chapters_to_db(book_data['book_id'], res['chapters'])
                rewritten_count += 1
        
        return rewritten_count

    def save_blueprint_to_db(self, data, genre, style_dna_str):
        # Pydanticãƒ¢ãƒ‡ãƒ«ã‹ã‚‰è¾æ›¸ã¸
        if isinstance(data, dict): data_dict = data
        else: data_dict = data.model_dump() # Should not happen based on return type of generate_universe_blueprint_phase1 logic which returns dict
        
        # Phase1ãŒè¾æ›¸ã§è¿”ã£ã¦ãã‚‹ã‚ˆã†ã«ä¿®æ­£æ¸ˆã¿ã ãŒå¿µã®ãŸã‚
        
        dna = json.dumps({
            "tone": data_dict['mc_profile']['tone'], 
            "personality": data_dict['mc_profile'].get('personality', ''),
            "style_mode": style_dna_str,
            "pov_type": "ä¸€äººç§°"
        }, ensure_ascii=False)
        
        ability_val = data_dict['mc_profile'].get('ability', '')
        
        bid = db.execute(
            "INSERT INTO books (title, genre, synopsis, concept, target_eps, style_dna, status, special_ability, created_at) VALUES (?,?,?,?,?,?,?,?,?)",
            (data_dict['title'], genre, data_dict['synopsis'], data_dict['concept'], 25, dna, 'active', ability_val, datetime.datetime.now().isoformat())
        )
        c_dna = json.dumps(data_dict['mc_profile'], ensure_ascii=False)
        monologue_val = data_dict['mc_profile'].get('monologue_style', '')
        db.execute("INSERT INTO characters (book_id, name, role, dna_json, monologue_style) VALUES (?,?,?,?,?)", (bid, data_dict['mc_profile']['name'], 'ä¸»äººå…¬', c_dna, monologue_val))
        
        # Initial Bible Creation
        db.execute("INSERT INTO bible (book_id, immutable, mutable, revealed, last_updated) VALUES (?,?,?,?,?)",
                   (bid, "{}", "{}", "[]", datetime.datetime.now().isoformat()))

        saved_plots = []
        for p in data_dict['plots']:
            full_title = f"ç¬¬{p['ep_num']}è©± {p['title']}"
            main_ev = f"{p.get('setup','')}->{p.get('climax','')}"
            scenes_json = json.dumps(p.get('scenes', []), ensure_ascii=False)
            db.execute(
                """INSERT INTO plot (book_id, ep_num, title, main_event, setup, conflict, climax, resolution, tension, status, scenes)
                   VALUES (?,?,?,?,?,?,?,?,?,?,?)""",
                (bid, p['ep_num'], full_title, main_ev, 
                 p.get('setup'), p.get('conflict'), p.get('climax'), p.get('resolution'), 
                 p.get('tension', 50), 'planned', scenes_json)
            )
            saved_plots.append(p)
        return bid, saved_plots

    def save_additional_plots_to_db(self, book_id, data_p2):
        saved_plots = []
        # data_p2 is dict (json.loads result)
        for p in data_p2['plots']:
            full_title = f"ç¬¬{p['ep_num']}è©± {p['title']}"
            main_ev = f"{p.get('setup','')}->{p.get('climax','')}"
            scenes_json = json.dumps(p.get('scenes', []), ensure_ascii=False)
            db.execute(
                """INSERT INTO plot (book_id, ep_num, title, main_event, setup, conflict, climax, resolution, tension, status, scenes)
                   VALUES (?,?,?,?,?,?,?,?,?,?,?)""",
                (book_id, p['ep_num'], full_title, main_ev, 
                 p.get('setup'), p.get('conflict'), p.get('climax'), p.get('resolution'), 
                 p.get('tension', 50), 'planned', scenes_json)
            )
            saved_plots.append(p)
        return saved_plots

    def save_chapters_to_db(self, book_id, chapters_list):
        count = 0
        if not chapters_list: return 0
            
        for ch in chapters_list:
            content = TextFormatter.format(ch['content'])
            w_state = json.dumps(ch.get('world_state', {}), ensure_ascii=False) if ch.get('world_state') else ""

            db.execute(
                """INSERT OR REPLACE INTO chapters (book_id, ep_num, title, content, summary, ai_insight, world_state, created_at)
                   VALUES (?,?,?,?,?,?,?,?)""",
                (book_id, ch['ep_num'], ch.get('title', f"ç¬¬{ch['ep_num']}è©±"), content, ch.get('summary', ''), '', w_state, datetime.datetime.now().isoformat())
            )
            db.execute("UPDATE plot SET status='completed' WHERE book_id=? AND ep_num=?", (book_id, ch['ep_num']))
            count += 1
        return count

# ==========================================
# Task Functions
# ==========================================
def mc_profile_str(mc_profile): return f"{mc_profile.get('name')} (æ€§æ ¼:{mc_profile.get('personality')}, å£èª¿:{mc_profile.get('tone')})"

async def task_plot_gen_phase2(engine, bid, genre, style, mc_personality, mc_tone, keywords, data1):
    print(f"Parallel Task: Generating Phase 2 for Book ID {bid}...")
    data2 = await engine.generate_universe_blueprint_phase2(genre, style, mc_personality, mc_tone, keywords, data1)

    if data2 and 'plots' in data2:
        saved_plots_p2 = engine.save_additional_plots_to_db(bid, data2)
        print(f"Phase 2 Plots Saved ({len(saved_plots_p2)} eps).")
        return data2['plots']
    else:
        print("Phase 2 Generation Failed.")
        return []

async def task_write_batch(engine, bid, start_ep, end_ep):
    book_info = db.fetch_one("SELECT * FROM books WHERE id=?", (bid,))
    plots = db.fetch_all("SELECT * FROM plot WHERE book_id=? ORDER BY ep_num", (bid,))
    mc = db.fetch_one("SELECT * FROM characters WHERE book_id=? AND role='ä¸»äººå…¬'", (bid,))

    try:
        style_dna_json = json.loads(book_info['style_dna'])
        saved_style = style_dna_json.get('style_mode', 'æ¨™æº–')
    except:
        saved_style = 'æ¨™æº–'
    mc_profile = json.loads(mc['dna_json']) if mc and mc['dna_json'] else {"name":"ä¸»äººå…¬", "tone":"æ¨™æº–"}
    mc_profile['monologue_style'] = mc.get('monologue_style', '') 

    for p in plots:
        if p.get('scenes'):
            try: p['scenes'] = json.loads(p['scenes'])
            except: pass

    full_data = {"book_id": bid, "title": book_info['title'], "mc_profile": mc_profile, "plots": [dict(p) for p in plots]}
    semaphore = asyncio.Semaphore(10)

    tasks = []
    print(f"Starting Machine-Gun Parallel Writing (Ep {start_ep} - {end_ep})...")

    target_plots = [p for p in plots if start_ep <= p['ep_num'] <= end_ep]

    for p in target_plots:
        ep_num = p['ep_num']
        tension = p.get('tension', 50)
        
        target_model = MODEL_LITE
        if tension >= 80 or ep_num == 1 or ep_num == 25:
            target_model = MODEL_PRO 
        else:
            target_model = MODEL_LITE
        
        tasks.append(engine.write_episodes(
            full_data, 
            ep_num, 
            ep_num, 
            style_dna_str=saved_style, 
            target_model=target_model, 
            semaphore=semaphore
        ))

    results = await asyncio.gather(*tasks)

    total_count = 0
    for res_data in results:
        if res_data and 'chapters' in res_data:
            c = engine.save_chapters_to_db(bid, res_data['chapters'])
            total_count += c
            
    print(f"Batch Done (Ep {start_ep}-{end_ep}). Total Episodes Written: {total_count}")
        
    return total_count, full_data, saved_style

async def task_analyze_marketing(engine, bid):
    print("Analyzing & Creating Marketing Assets...")
    evals, rewrite_targets, assets = await engine.analyze_and_create_assets(bid)
    return evals, rewrite_targets, assets

async def task_rewrite(engine, full_data, rewrite_targets, evals, saved_style):
    if not rewrite_targets: return 0
    print(f"Rewriting {len(rewrite_targets)} Episodes (Consistency & Quality Check)...")
    c = await engine.rewrite_target_episodes(full_data, rewrite_targets, evals, style_dna_str=saved_style)
    return c

# ==========================================
# 3. Main Logic (Headless)
# ==========================================
def load_seed():
    if not os.path.exists("story_seeds.json"):
        return {
            "genre": "ç¾ä»£ãƒ€ãƒ³ã‚¸ãƒ§ãƒ³",
            "keywords": "é…ä¿¡, äº‹æ•…, ç„¡åŒ",
            "personality": "å†·é™æ²ˆç€",
            "tone": "ä¿º",
            "hook_text": "é…ä¿¡åˆ‡ã‚Šå¿˜ã‚Œã§ä¸–ç•Œæœ€å¼·ãŒãƒãƒ¬ã‚‹",
            "style": "æ¨™æº–"
        }

    with open("story_seeds.json", "r", encoding='utf-8') as f:
        data = json.load(f)
        seed = random.choice(data['seeds'])
        tmpl = random.choice(seed['templates'])
        twists = ["è¨˜æ†¶å–ªå¤±", "å®Ÿã¯2å‘¨ç›®", "ç›¸æ£’ãŒãƒ©ã‚¹ãƒœã‚¹", "å¯¿å‘½ãŒæ®‹ã‚Šã‚ãšã‹"]
        twist = random.choice(twists)
        
        print(f"â˜… Selected: {seed['genre']} - {tmpl['type']}")
        return {
            "genre": seed['genre'],
            "keywords": f"{tmpl['keywords']}, {twist}",
            "personality": tmpl['mc_profile'],
            "tone": "ä¿º",
            "hook_text": tmpl['hook'],
            "style": "æ¨™æº–"
        }

def create_zip_package(book_id, title, marketing_data):
    print("Packing ZIP...")
    buffer = io.BytesIO()

    current_book = db.fetch_one("SELECT * FROM books WHERE id=?", (book_id,))
    db_chars = db.fetch_all("SELECT * FROM characters WHERE book_id=?", (book_id,))
    db_plots = db.fetch_all("SELECT * FROM plot WHERE book_id=? ORDER BY ep_num", (book_id,))
    chapters = db.fetch_all("SELECT * FROM chapters WHERE book_id=? ORDER BY ep_num", (book_id,))

    def clean_filename_title(t):
        return re.sub(r'[\\/:*?"<>|]', '', re.sub(r'^ç¬¬\d+è©±[\sã€€]*', '', t)).strip()

    keyword_dict = {}
    mc_char = next((c for c in db_chars if c['role'] == 'ä¸»äººå…¬'), None)
    if mc_char:
        try:
            dna = json.loads(mc_char['dna_json'])
            keyword_dict = dna.get('keyword_dictionary', {})
        except: pass

    with zipfile.ZipFile(buffer, "w", zipfile.ZIP_DEFLATED) as z:
        reg_info = f"ã€ã‚¿ã‚¤ãƒˆãƒ«ã€‘\n{title}\n\nã€ã‚ã‚‰ã™ã˜ã€‘\n{current_book.get('synopsis', '')}\n"
        z.writestr("00_ä½œå“ç™»éŒ²ç”¨ãƒ‡ãƒ¼ã‚¿.txt", reg_info)

        setting_txt = f"ã€ä¸–ç•Œè¦³ãƒ»ç‰¹æ®Šèƒ½åŠ›è¨­å®šã€‘\n{current_book.get('special_ability', 'ãªã—')}\n\n"
        setting_txt += "ã€ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼è¨­å®šã€‘\n"
        for char in db_chars:
            setting_txt += f"â–  {char['name']} ({char['role']})\n"
            if char.get('monologue_style'):
                setting_txt += f"  - ãƒ¢ãƒãƒ­ãƒ¼ã‚°ç™–: {char['monologue_style']}\n"
            try:
                dna = json.loads(char['dna_json'])
                for k, v in dna.items():
                    if k not in ['name', 'role', 'monologue_style']:
                        val_str = json.dumps(v, ensure_ascii=False) if isinstance(v, (dict, list)) else str(v)
                        setting_txt += f"  - {k}: {val_str}\n"
            except:
                setting_txt += f"  - è¨­å®šãƒ‡ãƒ¼ã‚¿: {char['dna_json']}\n"
            setting_txt += "\n"
        z.writestr("00_ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ãƒ»ä¸–ç•Œè¦³è¨­å®šè³‡æ–™.txt", setting_txt)

        plot_txt = f"ã€ã‚¿ã‚¤ãƒˆãƒ«ã€‘{title}\nã€å…¨è©±ãƒ—ãƒ­ãƒƒãƒˆæ§‹æˆæ¡ˆã€‘\n\n"
        for p in db_plots:
            plot_txt += f"--------------------------------------------------\n"
            plot_txt += f"ç¬¬{p['ep_num']}è©±ï¼š{p['title']}\n"
            plot_txt += f"--------------------------------------------------\n"
            plot_txt += f"ãƒ»ãƒ¡ã‚¤ãƒ³ã‚¤ãƒ™ãƒ³ãƒˆ: {p.get('main_event', '')}\n"
            plot_txt += f"ãƒ»å°å…¥ (Setup): {p.get('setup', '')}\n"
            plot_txt += f"ãƒ»å±•é–‹ (Conflict): {p.get('conflict', '')}\n"
            plot_txt += f"ãƒ»è¦‹ã›å ´ (Climax): {p.get('climax', '')}\n"
            plot_txt += f"ãƒ»çµæœ« (Resolution): {p.get('resolution', '')}\n"
            plot_txt += f"ãƒ»ãƒ†ãƒ³ã‚·ãƒ§ãƒ³: {p.get('tension', '-')}/100\n\n"
        z.writestr("00_å…¨è©±ãƒ—ãƒ­ãƒƒãƒˆæ§‹æˆæ¡ˆ.txt", plot_txt)

        for ch in chapters:
            clean_title = clean_filename_title(ch['title'])
            fname = f"chapters/{ch['ep_num']:02d}_{clean_title}.txt"
            body = TextFormatter.format(ch['content'], k_dict=keyword_dict)
            z.writestr(fname, body)
        
        if marketing_data:
            kinkyo = marketing_data.get('kinkyo_note', '')
            if kinkyo:
                z.writestr("00_è¿‘æ³ãƒãƒ¼ãƒˆ.txt", kinkyo)
            
            meta = f"ã€ã‚¿ã‚¤ãƒˆãƒ«ã€‘\n{title}\n\n"
            meta += f"ã€ã‚­ãƒ£ãƒƒãƒã‚³ãƒ”ãƒ¼ã€‘\n" + "\n".join(marketing_data.get('catchcopies', [])) + "\n\n"
            meta += f"ã€æ¤œç´¢ã‚¿ã‚°ã€‘\n{' '.join(marketing_data.get('tags', []))}\n\n"
            z.writestr("marketing_assets.txt", meta)
            
            try:
                z.writestr("marketing_raw.json", json.dumps(marketing_data, ensure_ascii=False))
            except: pass

    buffer.seek(0)
    return buffer.getvalue()

def send_email(zip_data, title):
    if not GMAIL_USER or not GMAIL_PASS:
        print("Skipping Email: Credentials not found.")
        return

    print(f"Sending Email to {TARGET_EMAIL}...")
    msg = MIMEMultipart()
    msg['Subject'] = f"ã€AI Novel Factoryã€‘{title} (Completed)"
    msg['From'] = GMAIL_USER
    msg['To'] = TARGET_EMAIL

    part = MIMEBase('application', 'zip')
    part.set_payload(zip_data)
    encoders.encode_base64(part)
    clean_title = re.sub(r'[\\/:*?"<>|]', '', title)
    part.add_header('Content-Disposition', f'attachment; filename="{clean_title}.zip"')
    msg.attach(part)

    try:
        with smtplib.SMTP_SSL("smtp.gmail.com", 465) as server:
            server.login(GMAIL_USER, GMAIL_PASS)
            server.send_message(msg)
        print("Email Sent Successfully!")
    except Exception as e:
        print(f"Email Failed: {e}")

async def main():
    if not API_KEY:
        print("Error: GEMINI_API_KEY is missing.")
        return

    engine = UltraEngine(API_KEY)

    print("Starting Factory Pipeline (Async / Structural Output)...")

    while True:
        try:
            seed = load_seed()
            
            print("Step 1a: Generating Plot Phase 1...")
            data1 = await engine.generate_universe_blueprint_phase1(
                seed['genre'], seed['style'], seed['personality'], seed['tone'], seed['keywords']
            )
            
            if not data1: 
                print("Plot Gen Phase 1 failed. Retrying in 10s...")
                await asyncio.sleep(1)
                continue

            bid, plots_p1 = engine.save_blueprint_to_db(data1, seed['genre'], seed['style'])
            print(f"Phase 1 Saved. ID: {bid}")
            
            print("Step 2: Starting Parallel Execution (Write P1 vs Gen P2)...")
            
            task_write_p1 = asyncio.create_task(
                task_write_batch(engine, bid, start_ep=1, end_ep=13)
            )
            
            task_gen_p2 = asyncio.create_task(
                task_plot_gen_phase2(
                    engine, bid, seed['genre'], seed['style'], seed['personality'], seed['tone'], seed['keywords'], data1
                )
            )
            
            count_p1, full_data_p1, saved_style = await task_write_p1
            await task_gen_p2
            
            print("Parallel Execution Completed. Proceeding to Write Phase 2...")

            count_p2, full_data_final, _ = await task_write_batch(engine, bid, start_ep=14, end_ep=25)
            
            full_data = full_data_final 

            evals, rewrite_targets, assets = await task_analyze_marketing(engine, bid)
            print(f"Rewriting Targets (Consistency & Low Score): {rewrite_targets}")

            if rewrite_targets:
                await task_rewrite(engine, full_data, rewrite_targets, evals, saved_style)

            book_info = db.fetch_one("SELECT title FROM books WHERE id=?", (bid,))
            title = book_info['title']
            
            zip_bytes = create_zip_package(bid, title, assets)
            send_email(zip_bytes, title)
            print(f"Mission Complete: {title}. Sleeping for next run...")
            
            await asyncio.sleep(10) 

        except Exception as e:
            print(f"Pipeline Critical Error: {e}")
            import traceback
            traceback.print_exc()
            await asyncio.sleep(10)

if __name__ == "__main__":
    asyncio.run(main())